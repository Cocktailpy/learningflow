{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# author https://www.kaggle.com/willkoehrsen/feature-selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction: Feature Selection\n",
    "In this notebook we will apply feature engineering to the manual engineered features built in two previous kernels. We will reduce the number of features using several methods and then we will test the performance of the features using a fairly basic gradient boosting machine model.\n",
    "\n",
    "The main takeaways from this notebook are:\n",
    "\n",
    "Going from 1465 total features to 536 and an AUC ROC of 0.783 on the public leaderboard\n",
    "A further optional step to go to 342 features and an AUC ROC of 0.782\n",
    "The full set of features was built in Part One and Part Two of Manual Feature Engineering\n",
    "\n",
    "We will use three methods for feature selection:\n",
    "\n",
    "Remove collinear features\n",
    "Remove features with greater than a threshold percentage of missing values\n",
    "Keep only the most relevant features using feature importances from a model\n",
    "We will also take a look at an example of applying PCA although we will not use this method for feature reduction.\n",
    "\n",
    "Standard imports for data science work. The LightGBM library is used for the gradient boosting machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# featuretools for automated feature engineering\n",
    "import featuretools as ft\n",
    "\n",
    "# matplotlit and seaborn for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 22\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings from pandas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# modeling \n",
    "import lightgbm as lgb\n",
    "\n",
    "# utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# memory management\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
